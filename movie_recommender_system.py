# -*- coding: utf-8 -*-
"""Movie recommender system.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1z77LcNfE-K94MpvwJUnpsBhNoyOETWNJ
"""

import numpy as np
import pandas as pd

movies=pd.read_csv('/content/tmdb_5000_movies.csv.zip')
credits=pd.read_csv('/content/tmdb_5000_credits.csv.zip')

movies.head()

movies.shape

credits.head()

credits.head()['cast'].values

credits.head()['crew'].values

# here we require cast and crew from the credits dataset
# so we merge credits and movies datasets together

# here we merge both the datasets on the basis of title

movies.merge(credits,on='title')

credits.shape

movies.shape

movies=movies.merge(credits,on='title')

movies.head(1)

# now here are so many things that are not required for us in our project
# so we are ready for the preprocessing and data wrangling and cleaning

# genres
#id
#keywords(basically tags)
#(original language) here we are not taking this feature as most of the films are english
#title
#overview( it is most important as we recommended on the basis of content)
#cast ( most of the peoples recommended on the basis of their favourite actors)
# crew( same reason)



movies=movies[['movie_id','title','overview','genres','keywords','cast','crew']]

movies.info()

movies.head()

movies.isnull().sum()

movies.dropna(inplace=True)  # we ought to drop because there is only 3 missing values and it does not impact much

movies.duplicated().sum() # we are checking is there any duplicated data or not

movies.iloc[0].genres

# we can clearly see that genres are in very tidious way and in multiple dictionary so we are try to preprocess on genres


#[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"},
# {"id": 878, "name": "Science Fiction"}]


# we have to put this generes in this format
#['Action','Adventure','Fantasy','SciFi]

import ast
ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')

def convert(obj):
  L=[]
  for i in ast.literal_eval(obj):
    L.append(i['name'])
  return L

movies['genres']=movies['genres'].apply(convert)

movies.head()

movies['keywords']=movies['keywords'].apply(convert)
movies.head()

# now processing in the cast column
movies['cast'][0]

# we only require top 3 cast from the movie as they are main
def convert3(obj):
  L=[]
  counter=0
  for i in ast.literal_eval(obj):
    if counter!=3:
      L.append(i['name'])
      counter+=1
    else:
      break
  return L

movies['cast']=movies['cast'].apply(convert3)

movies.head()

# now preprocessing for crew

movies['crew'][0]


# in this crew we only require that dictionary which have key job and value is director or producer

def fetch_director(obj):
  L=[]
  for i in ast.literal_eval(obj):
    if i['job']=='Director':
       L.append(i['name'])
       break
  return L

movies['crew']=movies['crew'].apply(fetch_director)

movies.head()

# now for overview
# we have to make list because we have to concatenate with other list

movies['overview'][0]

movies['overview']=movies['overview'].apply (lambda x:x.split())

movies.head()

# now we have to concatenate all the list

# we have to make our name into one name for example 'Sam Worthington' we have to remove space from the names.

movies['genres']=movies['genres'].apply(lambda x:[i.replace(" ","")for i in x])
# ScienceFiction this has done after apply this function
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" ","")for i in x])
# Cultureclash
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" ","")for i in x])
#SamWorthington
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" ","")for i in x])
#Sammendes

movies.head()

# now we add new column called 'tag' which is the concatenation of all the columns

movies['tags']=movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']

movies.head()

new_df=movies[['movie_id','title','tags']]
new_df.head()

# now this tags list converted into this list

new_df['tags']=new_df['tags'].apply(lambda x:" ".join(x))

new_df.head()

new_df['tags'][0]

new_df['tags']=new_df['tags'].apply(lambda x:x.lower())

new_df.head()

import nltk

from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()    # we used this  library because we have to do stemming and it has different lib

def stem(text):
  y=[]

  for i in text.split():
    y.append(ps.stem(i))

  return " ".join(y)

new_df['tags']=new_df['tags'].apply(stem)

# now we are at the point here we think about our basic idea of our project
# here we think that we have to recommend movie on the basis of which tags.... so we start thinking



# here lets see

new_df['tags'][0]

new_df['tags'][1]

# for example if we have to recommend some movie so we have to find out the similar words or same kind of text
# in these two but this is a text
# can we somehow change these text into numbers ..... the answer is yes
# we do the vectorization..... by assuming 5000 movies are like a point
# so we recommend those movies who are closest of each other

# the techniques are " bag of words"  called as vectorization

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=5000,stop_words='english')


#here we extract 5000 words from the text and remove all the stopwords
# here we used countvectorizer to form vector points

vectors=cv.fit_transform(new_df['tags']).toarray()

vectors.shape # here we convert all the movies into vector points

vectors[0] # here we can actually find that in a movies what are the most common 5000 words

# Get the feature names
cv.get_feature_names_out()

# in this array most of the words are same but considering two different words
# example-actions-action,activity-ativities....
# so we apply stemming....it makes all similar kind of words into a one single words

stem('in the 22nd century, a paraplegic marine is dispatched to the moon pandora on a unique mission, but becomes torn between following orders and protecting an alien civilization. action adventure fantasy sciencefiction cultureclash future spacewar spacecolony society spacetravel futuristic romance space alien tribe alienplanet cgi marine soldier battle loveaffair antiwar powerrelations mindandsoul 3d samworthington zoesaldana sigourneyweaver jamescameron')

# here there are total 4806 vectors within 5000 words

# now we calculate the closest distance between two vectors or two or more vectors
# and we calculate the cosine distance compare to eucledian distance as we are working on big data

# here distance is inversely proportional to the similarity

from sklearn.metrics.pairwise import cosine_similarity

cosine_similarity(vectors)

similarity=cosine_similarity(vectors)

similarity

similarity[0] # this is basically the distance of avatar with the other movie
# as 1 is the distance of avatar with avatar and second is the distance of avatar with 2nd movie

enumerate(similarity[0])

list(enumerate(similarity[0])) # it means that 0th index i.e avatar ka distance 0th index avatar se 1 h
                               # avater ka distance 1st movie se ye h

sorted(list(enumerate(similarity[0])),reverse=True) # now this sort is on the basis of index but we have to find on the basis of distance

sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]

# it means that 1216 index ki movie sabse closest hai avatar movie se

# here the diagonal element has always distance equal to 1

# now we are calculating the closest distance of avatar with other movie

def recommend(movie):
  movie_index=new_df[new_df['title'] == movie].index[0]
  distance = similarity[movie_index]
  movie_list=sorted(list(enumerate(distance)),reverse=True,key=lambda x:x[1])[1:6]

  for i in movie_list:
    print(new_df.iloc[i[0]].title)

recommend('Avatar') # these are the movies similar to the avatar

new_df.iloc[1216].title

recommend('Batman Begins')

# now this we have to convert into website

import pickle

pickle.dump(new_df,open('movies.pkl','wb'))

new_df['title'].values

new_df.to_dict()

pickle.dump(new_df.to_dict(),open('movie_dict.pkl','wb'))

pickle.dump(similarity,open('similarity.pkl','wb'))

